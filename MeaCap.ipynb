{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setup Environment"
      ],
      "metadata": {
        "id": "ju8SUXZKmcu0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZm4vj-oBndb",
        "outputId": "af0ee331-95f9-4da1-8a7a-0f63e90645fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Vision_LanguageFinal/MeaCap')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/myenv"
      ],
      "metadata": {
        "id": "w0ThwzIBQ9zK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install virtualenv\n"
      ],
      "metadata": {
        "id": "GpBl44iKDj08"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install python3.9\n",
        "!sudo apt-get install python3.9-distutils\n",
        "!sudo apt-get install python3.9-venv\n",
        "!sudo apt-get install python3.9-pip\n",
        "\n"
      ],
      "metadata": {
        "id": "NQhrTb6PDrOp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install virtualenv\n",
        "!virtualenv -p python3.9 /content/myenv\n",
        "!/content/myenv/bin/python --version\n"
      ],
      "metadata": {
        "id": "n3L905hhErxB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CXTGN9yAPwfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/myenv/bin/pip install -r requirements.txt\n",
        "!/content/myenv/bin/pip install sentence-transformers==2.2.2\n",
        "!/content/myenv/bin/pip install safetensors\n",
        "!/content/myenv/bin/pip install pycocoevalcap\n",
        "\n"
      ],
      "metadata": {
        "id": "ka_k-8fYCAKr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/myenv/bin/pip freeze"
      ],
      "metadata": {
        "id": "SbvPQWGtVp_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/myenv/bin/python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV8LotUlDTmK",
        "outputId": "7a81557e-de93-45be-ae6e-eab583e138e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generating the Captions"
      ],
      "metadata": {
        "id": "Zau1fbB0dXzP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Free"
      ],
      "metadata": {
        "id": "MrtEjeKwbx5b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/myenv/bin/python inference.py --use_prompt  --memory_id flickr30k --img_path ./image_example --lm_model_path ./checkpoints/CBART_one_billion\n"
      ],
      "metadata": {
        "id": "TeyldQnBSTO9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d282b8-04b2-4a78-f2c7-f630eed4d124"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: /content/myenv/bin/python: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text-Only-Training"
      ],
      "metadata": {
        "id": "5gSFPCX-VgK3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !/content/myenv/bin/python inference.py --memory_id coco --img_path ./image_example --lm_model_path ./checkpoints/CBART_COCO\n",
        "\n",
        "!/content/myenv/bin/python inference.py --memory_id coco --img_path ./image_example --lm_model_path ./checkpoints/CBART_COCO  --wte_model_path ./all-mpnet-base-v2\n",
        "\n",
        "# !/content/myenv/bin/python inference.py --memory_id coco --img_path ./image_example --lm_model_path ./checkpoints/CBART_COCO  --wte_model_path ./all-mpnet-base-v2 --parser_checkpoint /content/drive/MyDrive/Vision_LanguageFinal/MeaCap/flan-t5\n",
        "\n"
      ],
      "metadata": {
        "id": "tRBnIvPLZ9ED"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Validation Code\n"
      ],
      "metadata": {
        "id": "F8T42k3jmrXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/content/myenv/bin/python cocoeval.py"
      ],
      "metadata": {
        "id": "3TVf_RrapcTu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extra Scripts"
      ],
      "metadata": {
        "id": "llMdbvCbdiyW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7t_ujkLuUqwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WxRajyh8GfTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !/content/myenv/bin/python create_dataset.py"
      ],
      "metadata": {
        "id": "lRwVt_bOFzDu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/drive/MyDrive/Vision_LanguageFinal/MeaCap/image_example\n",
        "# !mkdir /content/drive/MyDrive/Vision_LanguageFinal/MeaCap/image_example"
      ],
      "metadata": {
        "id": "c1SjQa4z4Rtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !/content/myenv/bin/python karpathy_split.py"
      ],
      "metadata": {
        "id": "b7dT17RV234A"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !find /content/drive/MyDrive/Vision_LanguageFinal/MeaCap/image_example -type f | wc -l"
      ],
      "metadata": {
        "id": "bn1punjb-39o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add8c388-4ce0-4ba5-a6f3-a3c6314e4f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pwd"
      ],
      "metadata": {
        "id": "ANlBqsGS5gFa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !du -sh ."
      ],
      "metadata": {
        "id": "SUG3FUy25rjS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp KarpathySplit/* image_example/\n"
      ],
      "metadata": {
        "id": "C4iUKEP7ipK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !huggingface-cli login\n"
      ],
      "metadata": {
        "id": "6cX0XymVUxUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# # Load the model\n",
        "# model = SentenceTransformer('grammarly/coedit-large')\n",
        "\n",
        "# # Verify the model\n",
        "# print(\"Model loaded successfully!\")\n",
        "# model.save(\"/content/drive/MyDrive/Vision_LanguageFinal/MeaCap/flan-t5\")"
      ],
      "metadata": {
        "id": "8Dgai7kuU0rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !/content/myenv/bin/python prepare_embedding.py --memory_id combine_data --memory_path /content/drive/MyDrive/Vision_LanguageFinal/MeaCap/data/memory/big_data/big_data.json"
      ],
      "metadata": {
        "id": "gZ3iRcGiVHPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yi-6zhozVOek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import CLIPModel\n",
        "\n",
        "# model_name = \"openai/clip-vit-base-patch32\"\n",
        "# model_path = \"/content/HuggingFace/clip-vit-base-patch32\"\n",
        "\n",
        "# # Download the model and save it locally\n",
        "# CLIPModel.from_pretrained(model_name).save_pretrained(model_path)\n",
        "# print(f\"Model downloaded to {model_path}\")\n"
      ],
      "metadata": {
        "id": "6JnvpWnthsyF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import CLIPProcessor\n",
        "\n",
        "# model_name = \"openai/clip-vit-base-patch32\"\n",
        "# model_path = \"/content/HuggingFace/clip-vit-base-patch32\"\n",
        "\n",
        "# # Download processor files and save locally\n",
        "# processor = CLIPProcessor.from_pretrained(model_name)\n",
        "# processor.save_pretrained(model_path)\n",
        "\n",
        "# print(f\"Processor files saved to {model_path}\")\n"
      ],
      "metadata": {
        "id": "Xs8JtumBkRLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from safetensors.torch import load_file\n",
        "# from transformers import CLIPModel\n",
        "\n",
        "# # Path to safetensors file and output bin file\n",
        "# safetensors_path = \"/content/HuggingFace/clip-vit-base-patch32/model.safetensors\"\n",
        "# output_bin_path = \"/content/HuggingFace/clip-vit-base-patch32/pytorch_model.bin\"\n",
        "\n",
        "# # Load the safetensors model\n",
        "# state_dict = load_file(safetensors_path)\n",
        "\n",
        "# # Save as pytorch_model.bin\n",
        "# torch.save(state_dict, output_bin_path)\n",
        "# print(f\"Converted to PyTorch format and saved at {output_bin_path}\")\n"
      ],
      "metadata": {
        "id": "nshC6H0Zj1dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !/content/myenv/bin/python downloadclip.py"
      ],
      "metadata": {
        "id": "-8md0oTtoFTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !rm -rf /content/HuggingFace"
      ],
      "metadata": {
        "id": "lD-yxBsAkPpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XJ8KL_rKWTnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.chdir('/content/drive/MyDrive/Vision_LanguageFinal/MeaCap/Flickr30K')"
      ],
      "metadata": {
        "id": "DhGCkGq4gwXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir image_example\n",
        "# !unzip flickr30k-images.zip -d image_example"
      ],
      "metadata": {
        "id": "vlP5zkCpg5Xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !find /content/drive/MyDrive/Vision_LanguageFinal/MeaCap/Flickr30K/image_example/flickr30k-images -type f | wc -l"
      ],
      "metadata": {
        "id": "1n_-Zj7FLzG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# # Replace with the path to your folder\n",
        "# folder_path = \"./image_example/flickr30k-images\"\n",
        "\n",
        "# # Count the number of files in the folder\n",
        "# l = list(os.listdir(folder_path))\n",
        "# print(f\"Number of files in the folder: {len(l)}\")\n"
      ],
      "metadata": {
        "id": "Jr1ad29mm0Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.chdir(\"/content/drive/MyDrive/Vision_LanguageFinal/MeaCap\")"
      ],
      "metadata": {
        "id": "abV8NoO6oWHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import json\n",
        "\n",
        "# # Load the CSV file\n",
        "# annotations_df = pd.read_csv(\"/content/drive/MyDrive/Vision_LanguageFinal/MeaCap/Flickr30K/flickr_annotations_30k.csv\")\n",
        "# ground_truth_json = []\n",
        "\n",
        "# for _, row in annotations_df.iterrows():\n",
        "#     image_id = row['filename'].split('.')[0]  # Extract ID from filename\n",
        "#     captions = eval(row['raw'])  # Convert string to list of captions\n",
        "#     for caption in captions:\n",
        "#         ground_truth_json.append({\n",
        "#             \"image_id\": image_id,\n",
        "#             \"caption\": caption\n",
        "#         })\n",
        "# with open(\"/content/drive/MyDrive/Vision_LanguageFinal/MeaCap/Flickr30K/flickr_ground_truth.json\", \"w\") as f:\n",
        "#     json.dump(ground_truth_json, f, indent=4)\n"
      ],
      "metadata": {
        "id": "yGuWz__zol4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d7Wc7Mq5pvQV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}